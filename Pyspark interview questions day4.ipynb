{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e0395ac-90db-4e75-a220-e9a90aa3a4d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "PySpark Coding Challenge: Analyzing Employee Salaries\n",
    "\n",
    "Task: You have a dataset containing information about employee salaries in a company. Your task is to use PySpark to analyze the data and answer a few questions using aggregate functions.\n",
    "\n",
    "Dataset: The dataset is in CSV format and contains the following columns: employee_id, employee_name, department, salary.\n",
    "\n",
    "Questions:\n",
    "\n",
    "Calculate the total payroll cost for the company.\n",
    "\n",
    "Find the average salary for each department.\n",
    "\n",
    "Identify the highest-paid employee and their department.\n",
    "\n",
    "Calculate the total number of employees in each department.\n",
    "\n",
    "Sample Dataset:\n",
    "\n",
    "employee_id,employee_name,department,salary\n",
    "1,John Doe,Engineering,90000\n",
    "2,Jane Smith,Marketing,75000\n",
    "3,Michael Johnson,Engineering,105000\n",
    "4,Emily Davis,Marketing,80000\n",
    "5,Robert Brown,Engineering,95000\n",
    "6,Linda Wilson,HR,60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2429239e-4801-4a46-a852-3c684f1d4260",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Payroll Cost: 505000\n+-----------+-----------------+\n| department|       avg_salary|\n+-----------+-----------------+\n|Engineering|96666.66666666667|\n|  Marketing|          77500.0|\n|         HR|          60000.0|\n+-----------+-----------------+\n\nHighest-Paid Employee: Row(employee_name='Michael Johnson', department='Engineering', salary=105000)\n+-----------+---------------+\n| department|total_employees|\n+-----------+---------------+\n|Engineering|              3|\n|  Marketing|              2|\n|         HR|              1|\n+-----------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, avg, max, count\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"EmployeeAnalysis\").getOrCreate()\n",
    "\n",
    "# Load the dataset\n",
    "data = [\n",
    "    (1, \"John Doe\", \"Engineering\", 90000),\n",
    "    (2, \"Jane Smith\", \"Marketing\", 75000),\n",
    "    (3, \"Michael Johnson\", \"Engineering\", 105000),\n",
    "    (4, \"Emily Davis\", \"Marketing\", 80000),\n",
    "    (5, \"Robert Brown\", \"Engineering\", 95000),\n",
    "    (6, \"Linda Wilson\", \"HR\", 60000)\n",
    "]\n",
    "columns = [\"employee_id\", \"employee_name\", \"department\", \"salary\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Question 1: Calculate total payroll cost\n",
    "total_payroll = df.select(sum(\"salary\")).collect()[0][0]\n",
    "print(\"Total Payroll Cost:\", total_payroll)\n",
    "\n",
    "# Question 2: Average salary per department\n",
    "avg_salary_per_department = df.groupBy(\"department\").agg(avg(\"salary\").alias(\"avg_salary\"))\n",
    "avg_salary_per_department.show()\n",
    "\n",
    "\n",
    "# Question 3: Highest-paid employee and their department\n",
    "highest_paid_employee = df.orderBy(col(\"salary\").desc()).limit(1).select(\"employee_name\", \"department\", \"salary\").first()\n",
    "print(\"Highest-Paid Employee:\", highest_paid_employee)\n",
    "\n",
    "# Question 4: Total number of employees per department\n",
    "total_employees_per_department = df.groupBy(\"department\").agg(count(\"employee_id\").alias(\"total_employees\"))\n",
    "total_employees_per_department.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Pyspark interview questions day4",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
